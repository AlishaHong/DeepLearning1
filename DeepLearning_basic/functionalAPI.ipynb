{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본적인 모듈 임포트 방식\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(64, 64, 3))\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 10), dtype=float32, sparse=False, name=keras_tensor_24>\n"
     ]
    }
   ],
   "source": [
    "# 모듈에서 특정 클래스나 함수만 임포트하기\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "print(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# 입력 텐서 정의 (Functional API 방식)\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "# 레이어 정의\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# 출력 텐서 정의\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "\n",
    "model.compile(optimizer='adam',              # 최적화 알고리즘: Adam\n",
    "              loss='categorical_crossentropy', # 손실 함수: 다중 클래스 분류 문제에 적합한 categorical_crossentropy\n",
    "              metrics=['accuracy'])           # 평가 지표: 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.1065 - loss: 8.5425\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1392 - loss: 2.2857\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1742 - loss: 2.2223\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2841 - loss: 2.0026\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5075 - loss: 1.6191\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6811 - loss: 1.0340\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9466 - loss: 0.3199\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0663\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2397db239a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 데이터 (입력 데이터와 레이블)\n",
    "\n",
    "import numpy as np\n",
    "train_data = np.random.random((1000, 64, 64, 3))  # 1000개의 64x64 RGB 이미지\n",
    "train_labels = np.random.randint(10, size=(1000, 1))  # 10개의 클래스 중 하나로 레이블된 데이터\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)  # 원-핫 인코딩\n",
    "\n",
    "# 모델 학습\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)  # 10 에포크 동안 학습, 배치 크기는 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1174 - loss: 3.2082\n",
      "Test loss: 3.2432162761688232, Test accuracy: 0.10999999940395355\n"
     ]
    }
   ],
   "source": [
    "# 예시 테스트 데이터 (입력 데이터와 레이블)\n",
    "\n",
    "test_data = np.random.random((200, 64, 64, 3))  # 200개의 64x64 RGB 이미지\n",
    "test_labels = np.random.randint(10, size=(200, 1))  # 10개의 클래스 중 하나로 레이블된 데이터\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)  # 원-핫 인코딩\n",
    "\n",
    "# 모델 평가\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted class for first test sample: 0\n"
     ]
    }
   ],
   "source": [
    "# 예측 예제\n",
    "\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# 첫 번째 테스트 데이터에 대한 예측 결과 출력\n",
    "\n",
    "print(f'Predicted class for first test sample: {np.argmax(predictions[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 코드 설명\n",
    "# 모델 정의:\n",
    "\n",
    "# Input: Input 층을 사용하여 입력 크기를 정의합니다.\n",
    "# Conv2D: 2D 합성곱 층을 적용하여 이미지의 공간적 특징을 추출합니다.\n",
    "# Flatten: 2D 데이터를 1D 벡터로 변환합니다.\n",
    "# Dense: 완전 연결 층을 추가하여 최종 클래스 예측을 수행합니다.\n",
    "# Model: 입력과 출력을 연결하여 모델을 정의합니다.\n",
    "# 모델 컴파일:\n",
    "\n",
    "# optimizer: Adam 옵티마이저를 사용하여 학습합니다.\n",
    "# loss: 다중 클래스 분류 문제에 적합한 categorical_crossentropy 손실 함수를 사용합니다.\n",
    "# metrics: 모델 성능 평가를 위해 accuracy 지표를 사용합니다.\n",
    "# 모델 학습:\n",
    "\n",
    "# fit: 학습 데이터와 레이블을 사용하여 모델을 학습합니다. 에포크 수와 배치 크기를 지정할 수 있습니다.\n",
    "# 모델 평가:\n",
    "\n",
    "# evaluate: 테스트 데이터로 모델의 성능을 평가합니다. 손실 값과 정확도를 반환합니다.\n",
    "# 모델 예측:\n",
    "\n",
    "# predict: 새로운 데이터에 대한 예측을 수행합니다. 여기서는 첫 번째 테스트 샘플에 대해 예측된 클래스를 출력합니다.\n",
    "# 이 전체 과정은 딥러닝 모델을 구축하고, 컴파일하고, 학습시키며, 평가하고 예측하는 일반적인 순서를 따릅니다. 이 과정을 통해 모델을 실제 데이터에 적용하고, 원하는 작업(예: 분류)을 수행할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
