{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 즉시실행모드인지 확인\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1 \n",
    "b = 2 \n",
    "c = tf.math.add(a,b)\n",
    "\n",
    "c\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 제공\n",
    "# 자동미분 \n",
    "# 예측과 실제값과의 오차를 최소로 하는 함수식을 찾기위해 미분하는 과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# 스칼라\n",
    "\n",
    "a = tf.constant(1)\n",
    "print(a)\n",
    "print(tf.rank(a))   # 객체의 차수 확인\n",
    "\n",
    "# 자료형 변환\n",
    "a = tf.cast(a,tf.float32)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(0.6666666666666666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6666666666666666, shape=(), dtype=float64)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 사칙연산\n",
    "\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.add(a,b)\n",
    "print(c)\n",
    "d = tf.subtract(a,b)\n",
    "print(d)\n",
    "e = tf.multiply(a,b)\n",
    "print(e)\n",
    "f = tf.divide(a,b)\n",
    "f1 = tf.math.divide(a,b)\n",
    "print(f)\n",
    "print(f1)\n",
    "\n",
    "#나머지\n",
    "g = tf.math.mod(a,b)\n",
    "print(g)\n",
    "\n",
    "#몫\n",
    "h = tf.math.floordiv(a,b)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1차원 배열\n",
    "py_list = [10., 20., 30.]   # 파이썬 리스트\n",
    "num_arr = np.array([10.,10.,10.])   # 넘파이 배열\n",
    "\n",
    "# 텐서로 변환\n",
    "\n",
    "vec1 = tf.constant(py_list, dtype=tf.float32)\n",
    "vec2 = tf.constant(num_arr, dtype=tf.float32)\n",
    "\n",
    "print(vec1)\n",
    "print(vec2)\n",
    "\n",
    "# 파이썬 리스트배열은 tf.constant를 사용한 정수 변환이 어렵다.\n",
    "# 리스트를 먼저 정수로 변환한 뒤 텐서로의 변환이 가능함 \n",
    "\n",
    "\n",
    "print(tf.rank(vec1))\n",
    "print(tf.rank(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4.472136  5.477226  6.3245554], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(60.0, shape=(), dtype=float32)\n",
      "tf.Tensor(30.0, shape=(), dtype=float32)\n",
      "tf.Tensor(90.0, shape=(), dtype=float32)\n",
      "tf.Tensor([11. 21. 31.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 벡터연산\n",
    "\n",
    "add2 = vec1 + vec2\n",
    "add2\n",
    "\n",
    "print(tf.math.sqrt(add2))\n",
    "print(tf.math.divide(vec1,vec2))\n",
    "\n",
    "\n",
    "# 합계구하기 : 벡터를 구성하는 원소들의 합계를 구할 수 있다. \n",
    "# 합계는 스칼라로 표현됨\n",
    "\n",
    "print(tf.reduce_sum(vec1))\n",
    "print(tf.reduce_sum(vec2))\n",
    "print(tf.reduce_sum(vec1+vec2))\n",
    "\n",
    "# 브로드캐스팅 연산\n",
    "\n",
    "print(vec1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1 : [[10 20]\n",
      " [30 40]]\n",
      "mat2 : [[10 20]\n",
      " [30 40]]\n",
      "행렬곱 : [[ 700 1000]\n",
      " [1500 2200]]\n"
     ]
    }
   ],
   "source": [
    "# 행렬\n",
    "\n",
    "matrix = [[10,20],\n",
    "          [30,40]]\n",
    "\n",
    "mat1 = tf.constant(matrix)\n",
    "print(f'mat1 : {mat1}')\n",
    "\n",
    "tf.rank(mat1)\n",
    "\n",
    "\n",
    "vec1 = [10,20]\n",
    "vec2 = [30,40] \n",
    "# stack함수로 1차원배열을 위아래로 쌓기 \n",
    "mat2 = tf.stack([vec1, vec2])\n",
    "print(f'mat2 : {mat2}')\n",
    "\n",
    "# 행렬곱연산\n",
    "\n",
    "mat_mul = tf.matmul(mat1, mat2)\n",
    "print(f'행렬곱 : {mat_mul}')\n",
    "\n",
    "\n",
    "\n",
    "# 행렬곱계산 \n",
    "# 첫번쨰행 첫번째열\n",
    "# 첫번쨰행 두번쨰열\n",
    "# 두번째행 첫번째열\n",
    "# 두번째행 두번째열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3차원 텐서 : [[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]]\n",
      "shape : (3, 2, 4)\n",
      "rank : 3\n"
     ]
    }
   ],
   "source": [
    "# 3차원 텐서\n",
    "\n",
    "mat1 = [[1,2,3,4],[5,6,7,8]]\n",
    "mat2 = [[9,10,11,12],[13,14,15,16]]\n",
    "mat3 = [[17,18,19,20],[21,22,23,24]]\n",
    "\n",
    "tensor1 = tf.constant([mat1,mat2,mat3])\n",
    "print(f'3차원 텐서 : {tensor1}')\n",
    "print(f'shape : {tensor1.shape}')\n",
    "print(f'rank : {tf.rank(tensor1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack으로 쌓은 3차원텐서 : [[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]]\n"
     ]
    }
   ],
   "source": [
    "tensor2 = tf.stack([mat1,mat2,mat3])\n",
    "print(f'stack으로 쌓은 3차원텐서 : {tensor2}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4차원텐서 : [[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]]]\n",
      "\n",
      "\n",
      " [[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]]]]\n",
      "(2, 3, 2, 4)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 4차원 텐서\n",
    "\n",
    "tensor_rank_4 = tf.stack([tensor1,tensor2])\n",
    "print(f'4차원텐서 : {tensor_rank_4}')\n",
    "print(tensor_rank_4.shape)\n",
    "print(tf.rank(tensor_rank_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([23, 24])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3차원 텐서 인덱싱 \n",
    "\n",
    "print(tensor1)\n",
    "\n",
    "tensor1[0,1,1]\n",
    "\n",
    "# 23,24 출력하기 \n",
    "tensor1[-1,-1,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7]\n",
      " [ 8  9 10 11 12 13 14 15]\n",
      " [16 17 18 19 20 21 22 23]], shape=(3, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]], shape=(6, 4), dtype=int32)\n",
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 형태변환\n",
    "# 텐서의 형태변환은 넘파이 reshape 함수의 사용법과 비슷\n",
    "\n",
    "tensor = tf.constant(range(0,24))\n",
    "print(tensor)\n",
    "\n",
    "# 1차원 배열을 2차원으로 변환\n",
    "tensor1 = tf.reshape(tensor, [3,8])\n",
    "print(tensor1)\n",
    "\n",
    "# 행 지정해서 변환\n",
    "tensor2 = tf.reshape(tensor1, [-1,4])\n",
    "print(tensor2)\n",
    "\n",
    "# 2차원행렬을 다시 1차원으로\n",
    "tensor3 = tf.reshape(tensor2, [-1])\n",
    "print(tensor3)\n",
    "\n",
    "\n",
    "# 1차원 벡터를 3차원 텐서로\n",
    "tensor_vec = tf.reshape(tensor, [-1,3,4])\n",
    "print(tensor_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]])>\n",
      "(2, 3)\n",
      "Variable:0\n",
      "<bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]])>>\n"
     ]
    }
   ],
   "source": [
    "# 변수\n",
    "\n",
    "# 수많은 미분 연산산을 반복하면서 각각의 중간 연산결과를 저장할 때 변수를 이용한다.\n",
    "# 모델을 학습하는 중간단계마다 모델의 가중치 행렬을 변수에 저장하고, 계산을 반복하면서 변수의 값을 업데이트\n",
    "\n",
    "tensor1 = tf.constant([[1,2,3],[4,5,6]])\n",
    "tensor_var1 = tf.Variable(tensor1)\n",
    "print(tensor_var1)\n",
    "print(tensor_var1.shape)\n",
    "\n",
    "print(tensor_var1.name)\n",
    "print(tensor_var1.numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[ 8 10 12]\n",
      " [14 16 18]]\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[ 8, 10, 12],\n",
      "       [14, 16, 18]])>\n"
     ]
    }
   ],
   "source": [
    "# 변수 수정\n",
    "\n",
    "tensor_var1.assign([[7,8,9],[10,11,12]])\n",
    "print(tensor_var1.numpy())\n",
    "\n",
    "tensor_var1.assign_add([[1,2,3],[4,5,6]])\n",
    "print(tensor_var1.numpy())\n",
    "\n",
    "print(tensor_var1\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 10 12]\n",
      " [14 16 18]]\n",
      "tf.Tensor(\n",
      "[[ 8 10 12]\n",
      " [14 16 18]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 변수 -> 텐서\n",
    "\n",
    "tensor_again = tf.convert_to_tensor(tensor_var1)\n",
    "print(tensor_again.numpy())\n",
    "print(tensor_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.stateful_random_ops.Generator object at 0x0000023749F64FA0>\n",
      "tf.Tensor(\n",
      "[-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
      "  1.082245    0.6199966  -0.44402212  1.3048344 ], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[1.3716869 5.8239574 5.6396422 1.4726914 7.630952  2.4913976 5.246735\n",
      " 3.85999   0.6679337 5.914503 ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 자동미분\n",
    "\n",
    "# 데이터셋 생성\n",
    "# 시드값을 지정하여 Generator 생성\n",
    "g = tf.random.Generator.from_seed(2020)\n",
    "print(g)\n",
    "x = g.normal(shape = (10,))\n",
    "y = 3 * x + 2\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의\n",
    "\n",
    "def cal_mse(X,Y,a,b):\n",
    "    Y_pred = a * X + b \n",
    "    squared_error = (Y - Y_pred)**2\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    \n",
    "    return mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 21.206811904907227 , a : 0.43943047523498535, b : 0.40119490027427673\n",
      "epoch : 21, loss : 0.05340142920613289 , a : 2.7137272357940674, b : 2.184020519256592\n",
      "epoch : 41, loss : 0.010097725316882133 , a : 2.88142466545105, b : 2.1174652576446533\n",
      "epoch : 61, loss : 0.0025486552622169256 , a : 2.9410433769226074, b : 2.0596706867218018\n",
      "epoch : 81, loss : 0.0006438164855353534 , a : 2.9703845977783203, b : 2.0300068855285645\n",
      "epoch : 101, loss : 0.00016263902944047004 , a : 2.9851152896881104, b : 2.0150821208953857\n",
      "epoch : 121, loss : 4.108121356694028e-05 , a : 2.9925191402435303, b : 2.007580041885376\n",
      "epoch : 141, loss : 1.037863694364205e-05 , a : 2.9962399005889893, b : 2.003809928894043\n",
      "epoch : 161, loss : 2.6213424462184776e-06 , a : 2.998110055923462, b : 2.0019147396087646\n",
      "epoch : 181, loss : 6.618389534196467e-07 , a : 2.9990503787994385, b : 2.000962257385254\n"
     ]
    }
   ],
   "source": [
    "# tf.GradientTape로 자동 미분 과정을 기록\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "EPOCHE = 200\n",
    "\n",
    "for epoch in range(EPOCHE):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse = cal_mse(x, y, a, b)\n",
    "    \n",
    "    grads = tape.gradient(mse, {'a': a, 'b': b})\n",
    "    d_a, d_b = grads['a'], grads['b']\n",
    "        \n",
    "    a.assign_sub(d_a * 0.05)\n",
    "    b.assign_sub(d_b * 0.05)\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'epoch : {epoch+1}, loss : {mse.numpy()} , a : {a.numpy()}, b : {b.numpy()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
